{"cells":[{"cell_type":"markdown","source":["## Importing the required libraries"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import udf\nfrom pyspark.sql.types import *\nimport re\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import regexp_replace\nfrom pyspark.sql.types import Row\nfrom pyspark.sql.functions import desc"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["## Reading the file using 'spark-xml' library"],"metadata":{}},{"cell_type":"code","source":["df = spark.read.format(\"com.databricks.spark.xml\") \\\n    .options(rowTag=\"page\") \\\n    .load(\"/FileStore/tables/Wikipedia_20180701215740-19677.xml\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["## Extracting The required Columns"],"metadata":{}},{"cell_type":"code","source":["new_df = df.select('title','revision.text._VALUE').dropna()\nnew_df = new_df.filter(~col('title').contains(\":\"))\nnew_df = new_df.withColumn('title',regexp_replace('title',' ','_'))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Creating the regex to extract the links"],"metadata":{}},{"cell_type":"code","source":["# this regex extracts the links\nmy_regex = re.compile(r'\\[+([^#,\\'\\-\\(].*?)[\\]|#]+')\n\n# this regex is used to extract those links which do not contain colon, comma and ampersand\ncheck_regex = re.compile(r'[:,&]')"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Function to calculate the node scores"],"metadata":{}},{"cell_type":"code","source":["def points(text):\n  list_links = my_regex.findall(text)\n  accepted_links = [link for link in list_links if len(check_regex.findall(link)) == 0]\n  return (1.0/float(len(accepted_links)))\n\nudf_points = udf(points,DoubleType())"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## Applying the transformation to the Dataframe"],"metadata":{}},{"cell_type":"code","source":["df_score = new_df.withColumn('node_score',udf_points('_VALUE')).select('title','node_score')\ndf_score = df_score.alias('df_score')"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Flattening the Link Array"],"metadata":{}},{"cell_type":"code","source":["def to_link(row):\n  t = row.title\n  redirect_list = my_regex.findall(row._VALUE)\n  result = []\n  for redirect in redirect_list:\n    if(len(check_regex.findall(redirect)) > 0):\n      continue;\n    l = redirect.replace(\" \",\"_\")\n    l = l.replace(\",\",\"_\")\n    l = l.replace(\"&amp\", \"&\")\n    row = Row(title=t,link=l)\n    result.append(row)\n  return result"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## Applying the Flatten transformation"],"metadata":{}},{"cell_type":"code","source":["df_link = spark.createDataFrame(new_df.rdd.flatMap(to_link))\ndf_link = df_link.alias('df_link')"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Extracting Only those links which are in title"],"metadata":{}},{"cell_type":"code","source":["good_df = df_score.join(df_link,df_score.title == df_link.link,how=\"inner\").select('df_link.link','df_link.title')\ngood_df = good_df.alias('good_df')"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["## Applying join to get scores besides good links"],"metadata":{}},{"cell_type":"code","source":["joinResult = good_df.join(df_score,good_df.title == df_score.title,how=\"inner\").select('good_df.link','df_score.node_score')"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["## Caclulating the rank"],"metadata":{}},{"cell_type":"code","source":["rank = joinResult.groupBy('link').sum('node_score').withColumnRenamed('sum(node_score)','rank').orderBy(desc('rank'))\nrank.show()"],"metadata":{},"outputs":[],"execution_count":22}],"metadata":{"name":"PageRankWikipedia","notebookId":1929128962256823},"nbformat":4,"nbformat_minor":0}
